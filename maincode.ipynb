{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python_torch",
      "language": "python",
      "name": "pytorch36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2-CSlkmNluw"
      },
      "source": [
        "# Run this every time you open the spreadsheet\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5xo73cmIGNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f399eb-771a-4b30-d204-11c3e0836daa"
      },
      "source": [
        "! git clone https://github.com/heyyjudes/AI4ALL2021-NLP.git\n",
        "! mv AI4ALL2021-NLP/data .\n",
        "! mv AI4ALL2021-NLP/lib ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI4ALL2021-NLP'...\n",
            "remote: Enumerating objects: 791, done.\u001b[K\n",
            "remote: Counting objects: 100% (294/294), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 791 (delta 134), reused 287 (delta 130), pack-reused 497\u001b[K\n",
            "Receiving objects: 100% (791/791), 53.14 MiB | 20.54 MiB/s, done.\n",
            "Resolving deltas: 100% (408/408), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVz4p5rpBcok"
      },
      "source": [
        "Run the following cell to import our own lib module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBiqEPWGBSYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e6525d-a2d9-4496-b427-8be61f095bd2"
      },
      "source": [
        "from lib.lib import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2cFU1NSmMNh",
        "outputId": "89ed09a3-40ed-47b4-ebb4-caecab352d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI4ALL2021-NLP\tdata  lib  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hx4au04Ew-k"
      },
      "source": [
        "# Load and inspect the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fycp6AHEEw-l"
      },
      "source": [
        "# Load the data.\n",
        "# This function returns tweets and test_tweets, both lists of tweets\n",
        "\n",
        "tweets, test_tweets = read_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRj_qCb8OKtL"
      },
      "source": [
        "### Tweets from read_data()\n",
        "t.category: category tweet is in {\"None\", \"Food\", \"Water\", \"Energy\", \"Medical\"}  \n",
        "t.tokenList : list of words in the tweet  \n",
        "t.tokenSet: unique list of words in tweet    \n",
        "t.\\_bigramList: list of bigrams  \n",
        "t.\\_featureSet: list of all features (e.g. bigrams and unigrams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "yhs9BbhvEw-w"
      },
      "source": [
        "# Learn a Naive Bayes classifier\n",
        "\n",
        "To construct our Naive Bayes classifier, we first need to calculate two things:\n",
        "\n",
        "### Prior probabilities of categories\n",
        "We need to calculate $P(C_i)$ for each category $C_i \\in \\{\\text{Energy}, \\text{Food}, \\text{Medical}, \\text{Water}, \\text{None}\\}$.\n",
        "\n",
        "We estimate $P(C_i)$ by $\\frac{\\text{# tweets about }C_i}{\\text{# tweets}}$\n",
        "\n",
        "### Conditional probabilities of tokens\n",
        "For each token (i.e. word) $x_j$ and each category $C_i$, we need to calculate $P(x_j|C_i)$.\n",
        "\n",
        "We estimate $P(x_j|C_i) = \\frac{P(x_j \\text{ and } C_i)}{P(C_i)}$ by $\\frac{\\text{# tweets about }C_i \\text{ containing }x_j}{\\text{# tweets about }C_i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTxLX4LuEw-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "384c2e71-4bc2-4f45-9df9-816904146eff"
      },
      "source": [
        "# Exercise 1\n",
        "\n",
        "# The function below has two arguments: a list of tweets, and a category c\n",
        "# which is a string equal to one of \"Energy\", \"Food\", \"Medical\", \"Water\", \"None\".\n",
        "# The function should calculate the two things described above.\n",
        "# Fill in the blanks.\n",
        "\n",
        "\n",
        "def calc_probs(tweets, c):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        tweets: a list of tweets\n",
        "        c: a string representing a category; one of \"Energy\", \"Food\", \"Medical\", \"Water\", \"None\".\n",
        "    Returns:\n",
        "        prob_c: the prior probability of category c - P(c)\n",
        "        token_probs: a Counter mapping each token to P(token|category c) -\n",
        "    \"\"\"\n",
        "    ##### YOUR CODE HERE ####\n",
        "\n",
        "    # Step 1: Calculate the total number of tweets\n",
        "    num_tweets = len(tweets)\n",
        "    # Step 2: Calculate the number of tweets that are about category c.\n",
        "    # Save the answer to a variable called num_tweets_about_c.\n",
        "    # Remember c is a string, and you can get the category of a tweet via tweet.category\n",
        "    num_tweets_about_c = 0\n",
        "    for tweet in tweets:\n",
        "      if c == tweet.category:\n",
        "          num_tweets_about_c += 1\n",
        "\n",
        "    # Step 3: Calculate the probability of category c using the answers from Steps 1 and 2.\n",
        "    prob_c = num_tweets_about_c / num_tweets\n",
        "\n",
        "    # Step 4: Create an empty Counter called token_counts.\n",
        "    # (We will use it to map each token to the number of category-c tweets containing that token.)\n",
        "    token_counts= Counter()\n",
        "\n",
        "    # Step 5: Use a for-loop to iterate over the list of tweets.\n",
        "    # Use an if-statement to check whether the tweet is in category c.\n",
        "    # If it is, iterate over the tokens of the tweet (which you can access via tweet.tokenSet) using a for-loop.\n",
        "    # For each token, increment its count in token_counts.\n",
        "\n",
        "    for tweet in tweets:\n",
        "      if c == tweet.category:\n",
        "        for token in tweet.tokenSet:\n",
        "          token_counts[token] += 1\n",
        "\n",
        "    # Step 6: Create an empty Counter called token_probs.\n",
        "    token_probs = Counter()\n",
        "    # (We will use it to map each token to P(token | category c),\n",
        "    # i.e. the fraction of all category-c tweets that contain the token)\n",
        "\n",
        "\n",
        "    # Step 7: Now fill token_probs.\n",
        "    # For each token->count in token_counts, you want to add token->fraction to token_probs.\n",
        "    # Use a for-loop over token_counts.\n",
        "    # Remember that when you iterate over a dictionary/Counter, you access the keys.\n",
        "        # You'll need to use the variable num_tweets_about_c.\n",
        "    for token in token_counts.keys():\n",
        "\n",
        "        token_probs[token] += token_counts[token]/num_tweets_about_c\n",
        "    ##### END CODE HERE ####\n",
        "\n",
        "    print(\"Class {:s} has prior probability {:.2f}\".format(c, prob_c))\n",
        "\n",
        "    ##### EXERCISE STARTS HERE ####\n",
        "\n",
        "    # Write some code to nicely-print the top most common tokens for this category.\n",
        "    # Note that token_probs.most_common(10) gives you the 10 most common tokens in the counter,\n",
        "    # as a list of (token, probability) pairs. This is another convenient feature of Counters!\n",
        "\n",
        "    ##### EXERCISE ENDS HERE ####\n",
        "\n",
        "    return prob_c, token_probs\n",
        "\n",
        "\n",
        "prob_food, token_probs_food = calc_probs(tweets, \"Food\")\n",
        "prob_water, token_probs_water = calc_probs(tweets, \"Water\")\n",
        "prob_energy, token_probs_energy = calc_probs(tweets, \"Energy\")\n",
        "prob_medical, token_probs_medical = calc_probs(tweets, \"Medical\")\n",
        "prob_none, token_probs_none = calc_probs(tweets, \"None\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Food has prior probability 0.47\n",
            "Class Water has prior probability 0.09\n",
            "Class Energy has prior probability 0.12\n",
            "Class Medical has prior probability 0.04\n",
            "Class None has prior probability 0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "EvlvGvP9Ew-5"
      },
      "source": [
        "### See what your model has learnt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgdCiGL_Ew-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d459c8e2-9d48-467f-a7a8-f07d0448c69f"
      },
      "source": [
        "# For each category c, print out the tokens that maximize P(c|token)\n",
        "\n",
        "token_probs = {'Food': token_probs_food, 'Water': token_probs_water, 'Energy': token_probs_energy, 'Medical': token_probs_medical,'None': token_probs_none}\n",
        "prior_probs = {'Food': prob_food, 'Water': prob_water, 'Energy': prob_energy, 'Medical': prob_medical, 'None': prob_none}\n",
        "\n",
        "most_discriminative(tweets, token_probs, prior_probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MOST DISCRIMINATIVE TOKENS: \n",
            "\n",
            "TOKEN                P(Energy|token)\n",
            "b'dark'              0.8029\n",
            "b'powers'            0.8029\n",
            "b'generator'         0.7654\n",
            "b'batteries'         0.7559\n",
            "b'class'             0.7534\n",
            "b'sandysucks'        0.7534\n",
            "b'flashlights'       0.7455\n",
            "b'masks'             0.7334\n",
            "b'11/3'              0.6736\n",
            "b'90'                0.6707\n",
            "\n",
            "TOKEN                P(Food|token)\n",
            "b'canned'            0.9784\n",
            "b'non-perishable'    0.9771\n",
            "b'serve'             0.9663\n",
            "b'perishable'        0.9562\n",
            "b'cook'              0.9511\n",
            "b'soup'              0.9489\n",
            "b'sandwiches'        0.9489\n",
            "b'thanksgiving'      0.9441\n",
            "b'rice'              0.9441\n",
            "b'pasta'             0.9383\n",
            "\n",
            "TOKEN                P(Medical|token)\n",
            "b'meds'              0.8229\n",
            "b'aid'               0.8008\n",
            "b'4t-5t'             0.7360\n",
            "b'medicine'          0.7360\n",
            "b'medications'       0.7360\n",
            "b'ups'               0.7360\n",
            "b'ointment'          0.7360\n",
            "b'prescription'      0.7360\n",
            "b'pull'              0.6596\n",
            "b'kits'              0.6596\n",
            "\n",
            "TOKEN                P(None|token)\n",
            "b'everyone'          0.8955\n",
            "b'last'              0.8809\n",
            "b'feel'              0.8809\n",
            "b'im'                0.8618\n",
            "b'irene'             0.8604\n",
            "b'...'               0.8601\n",
            "b'away'              0.8451\n",
            "b'..'                0.8340\n",
            "b'thing'             0.8314\n",
            "b'atlantic'          0.8314\n",
            "\n",
            "TOKEN                P(Water|token)\n",
            "b'bottled'           0.9059\n",
            "b'gallon'            0.8307\n",
            "b'jugs'              0.7970\n",
            "b'water'             0.7823\n",
            "b'gallons'           0.7266\n",
            "b'feet'              0.6625\n",
            "b'parks'             0.6625\n",
            "b'liter'             0.6625\n",
            "b'spring'            0.6625\n",
            "b'flood'             0.6625\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVpz9YqPEw_B"
      },
      "source": [
        "# Build a Naive Bayes classifier\n",
        "\n",
        "Now we've calculated $P(C_i)$ and $P(x_j|C_i)$, we can classify any tweet!\n",
        "\n",
        "Given a tweet which is a set of tokens $\\{x_1,...,x_n\\}$, the posterior probability of each category $C_i$ is\n",
        "\n",
        "$P(C_i | x_1,...,x_n) \\propto P(C_i) \\times P(x_1|C_i) \\times P(x_2|C_i) ... \\times P(x_n|C_i)$\n",
        "\n",
        "We just need to calculate this for each category then determine which is largest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "515jRdXUEw_C"
      },
      "source": [
        "# Exercise 2.1\n",
        "\n",
        "# Complete this function that calculates the posterior probability of P(c|tweet).\n",
        "\n",
        "def get_posterior_prob_attempt(tweet, prob_c, token_probs):\n",
        "    \"\"\"Calculate the posterior P(c|tweet).\n",
        "    (Actually, calculate something proportional to it).\n",
        "\n",
        "    Inputs:\n",
        "        tweet: a tweet\n",
        "        prob_c: the prior probability of category c\n",
        "        token_probs: a Counter mapping each token P(token|c)\n",
        "    Return:\n",
        "        The posterior P(c|tweet).\n",
        "    \"\"\"\n",
        "\n",
        "    ##### YOUR CODE STARTS HERE #####\n",
        "\n",
        "    # Hint: first set posterior to prob_c, then use a for-loop over tweet.tokenSet\n",
        "    # to repeatedly multiply posterior by P(token|c)\n",
        "    posterior = prob_c\n",
        "    for num in tweet.tokenSet:\n",
        "      posterior *= token_probs[num]\n",
        "\n",
        "    ##### YOUR CODE ENDS HERE #####\n",
        "\n",
        "    return posterior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx6MHABYEw_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10db5e55-4b50-4842-d1a7-60c9a2051e66"
      },
      "source": [
        "# Now you've written the function, look at the output for P(Energy|\"No power in Riverdale\").\n",
        "riverdale_tweet = Tweet(\"No power in Riverdale\", \"Energy\", \"need\")\n",
        "print(\"P(Energy|'No power in Riverdale') = \", get_posterior_prob_attempt(riverdale_tweet, prob_energy, token_probs_energy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Energy|'No power in Riverdale') =  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NTXmKcSEw_P"
      },
      "source": [
        "What's gone wrong?\n",
        "\n",
        "Try editing your function above to print out each `token` and `token_probs[token]`.\n",
        "\n",
        "Can you see what went wrong? How might you fix it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6ssXuPlEw_Q"
      },
      "source": [
        "# Exercise 2.2\n",
        "\n",
        "# Copy your solution to exercise 2.1 here and make the fix we discussed in the previous cell\n",
        "\n",
        "def get_posterior_prob(tweet, prob_c, token_probs):\n",
        "    \"\"\"Calculate the posterior P(c|tweet).\n",
        "    (Actually, calculate something proportional to it).\n",
        "\n",
        "    Inputs:\n",
        "        tweet: a tweet\n",
        "        prob_c: the prior probability of category c\n",
        "        token_probs: a Counter mapping each token P(token|c)\n",
        "    Return:\n",
        "        The posterior P(c|tweet).\n",
        "    \"\"\"\n",
        "\n",
        "    ##### YOUR CODE STARTS HERE #####\n",
        "\n",
        "    # Hint 1: first set posterior to prob_c, then use a for-loop over tweet.tokenSet\n",
        "    # to repeatedly multiply posterior by P(token|c)\n",
        "    # Hint 2: what happens when you multiply by 0\n",
        "    posterior = prob_c\n",
        "    for token in tweet.tokenSet:\n",
        "      if token not in token_probs.keys():\n",
        "        posterior *= 0.001\n",
        "      else:\n",
        "        posterior *= token_probs[token]\n",
        "\n",
        "\n",
        "    ##### YOUR CODE ENDS HERE #####\n",
        "\n",
        "    return posterior"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpuGt6G9Ew_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f371592-9002-4b2b-8d56-ddad9d2639de"
      },
      "source": [
        "# Try out our new function\n",
        "riverdale_tweet = Tweet(\"No power in Riverdale\", \"Energy\", \"need\")\n",
        "print(\"P(Energy|'No power in Riverdale') = \", get_posterior_prob(riverdale_tweet, prob_energy, token_probs_energy))\n",
        "\n",
        "# double check if we don't have zero probability words it is still fine\n",
        "riverdale_tweet = Tweet(\"No power\", \"Energy\", \"need\")\n",
        "print(\"P(Energy|'No power') = \", get_posterior_prob_attempt(riverdale_tweet, prob_energy, token_probs_energy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Energy|'No power in Riverdale') =  2.8060018903591684e-06\n",
            "P(Energy|'No power') =  0.00921972049689441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B18ZOAIXEw_b"
      },
      "source": [
        "# This cell defines the classification function, that takes a tweet\n",
        "# and decides which category is most likely using the posteriors you just calculated.\n",
        "\n",
        "\n",
        "# OPTIONAL EXERCISE (come back to it once you've reached the end of the notebook).\n",
        "# Rewrite this function to be less repetitive i.e. don't repeat things 5 times.\n",
        "# There are several possible solutions; you might want to use lists or dictionaries.\n",
        "# You might also want to rewrite the earlier code that computed prob_food, token_probs_food etc.\n",
        "\n",
        "\n",
        "def classify_nb(tweet):\n",
        "    \"\"\"Classifies a tweet. Calculates the posterior P(c|tweet) for each category c,\n",
        "    and returns the category with largest posterior.\n",
        "    Input:\n",
        "        tweet\n",
        "    Output:\n",
        "        string equal to most-likely category for this tweet\n",
        "    \"\"\"\n",
        "    ##### YOUR CODE STARTS HERE #####\n",
        "    # Hint 1: get posterior probability using the function you just wrote for: food, water, energy, medical and none\n",
        "    posterior_food_prob = get_posterior_prob(tweet, prob_food, token_probs_food)\n",
        "    posterior_water_prob = get_posterior_prob(tweet, prob_water, token_probs_water)\n",
        "    posterior_energy_prob = get_posterior_prob(tweet, prob_energy, token_probs_energy)\n",
        "    posterior_medical_prob = get_posterior_prob(tweet, prob_medical, token_probs_medical)\n",
        "    posterior_none_prob = get_posterior_prob(tweet, prob_none, token_probs_none)\n",
        "\n",
        "    # Hint 2: find max posterior probability of all the probabilities you just found\n",
        "    max_posterior = max([posterior_food_prob, posterior_water_prob, posterior_energy_prob, posterior_medical_prob, posterior_none_prob])\n",
        "\n",
        "    # Hint 3: output the probability that corresponds to the maximum posterior probability\n",
        "    if posterior_food_prob == max_posterior:\n",
        "        return 'Food'\n",
        "    elif posterior_water_prob == max_posterior:\n",
        "        return 'Water'\n",
        "    elif posterior_energy_prob == max_posterior:\n",
        "        return 'Energy'\n",
        "    elif posterior_medical_prob == max_posterior:\n",
        "        return 'Medical'\n",
        "    else:\n",
        "        return 'None'\n",
        "\n",
        "\n",
        "    ##### YOUR CODE ENDS HERE #####"
      ],
      "execution_count": null,
      "outputs": []
    },
